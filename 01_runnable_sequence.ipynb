{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e621ea7",
   "metadata": {},
   "source": [
    "## Sequence Runnable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "813d9882",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.runnables import RunnableSequence\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d683a1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This joke is a play on words. The term \"hard drive\" is typically used to refer to the storage device in computers that store data. In this joke, it is being used in a literal sense to imply that the robot had a hard time driving (or hitting) the tennis ball, hence why it was bad at tennis.\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "prompt_1 = PromptTemplate(\n",
    "    template=\"Tell me a good joke on the topic of {topic}.\", \n",
    "    input_variables=[\"topic\"],\n",
    ")\n",
    "\n",
    "prompt_2 = PromptTemplate(\n",
    "    template=\"Explain the joke: {joke}\",\n",
    "    input_variables=[\"joke\"],\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "runnable = RunnableSequence(prompt_1, llm, parser, prompt_2, llm, parser)\n",
    "\n",
    "output = runnable.invoke({\"topic\": \"AI\"})\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93172745",
   "metadata": {},
   "source": [
    "## Parallel Runnable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d416812d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tweet': '\"Just finished debugging my code and feeling like a coding wizard ðŸ’»âœ¨ #programming #codinglife\"', 'linkedin_post': \"Excited to share my latest project in programming - I just finished creating a new web application from scratch using HTML, CSS, and JavaScript. It was challenging but incredibly rewarding to see it come to life. Can't wait to continue learning and growing in the programming world. #programming #webdevelopment #codingjourney\"}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.runnables import RunnableSequence, RunnableParallel\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "load_dotenv()\n",
    "\n",
    "prompt_1 = PromptTemplate(\n",
    "    template = \"Generate a tweet on this topic: {topic}\",\n",
    "    input_variables = [\"topic\"],    \n",
    ")\n",
    "\n",
    "prompt_2 = PromptTemplate(\n",
    "    template = \"Generate a LinkedIn post on this topic: {topic}\",\n",
    "    input_variables = [\"topic\"],    \n",
    ")\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "parallel_chain = RunnableParallel({\n",
    "    \"tweet\": RunnableSequence(prompt_1, llm, parser),\n",
    "    \"linkedin_post\": RunnableSequence(prompt_2, llm, parser),\n",
    "})\n",
    "\n",
    "output = parallel_chain.invoke({'topic': 'Programming'})\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296d2581",
   "metadata": {},
   "source": [
    "## Passthrough Runnable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d641b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Joke': 'Why did the robot go to therapy?\\nBecause it had too many bytes of emotional baggage!', 'explain': 'This joke is a play on words combining technology terms and emotional concepts. In the joke, \"bytes\" is a unit of measurement for data in computing, but it is used humorously here to refer to emotional baggage. The idea is that the robot had accumulated too much emotional baggage, so it needed to go to therapy to unpack and deal with it.'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel, RunnableSequence\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "prompt_1 = PromptTemplate(\n",
    "    template=\"Generate a joke for me in this topic: {topic}\",\n",
    "    input_variables=[\"topic\"]\n",
    ")\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "prompt_2 = PromptTemplate(\n",
    "    template=\"Explain this joke to me: {joke}\",\n",
    "    input_variables=[\"joke\"]\n",
    ")\n",
    "\n",
    "joke_gen_chain = RunnableSequence(prompt_1, llm, parser)\n",
    "\n",
    "parallel_chain = RunnableParallel({\n",
    "    'Joke': RunnablePassthrough(),\n",
    "    \"explain\": RunnableSequence(prompt_2, llm, parser)\n",
    "})\n",
    "\n",
    "final_chain = RunnableSequence(joke_gen_chain, parallel_chain)\n",
    "\n",
    "output = final_chain.invoke({'topic': 'AI'})\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b2bec2",
   "metadata": {},
   "source": [
    "## Lambda Runnable\n",
    "* To convert python function into runnable.\n",
    "- eg: Make a function in python which clean the data. And you can convert that output into runnable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6fbe183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joke': \"Why did the AI break up with the calculator?\\n\\nBecause it couldn't handle its division problems!\", 'word_count': 16}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableSequence, RunnableParallel, RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def number_words(sentence: str):\n",
    "    return len(sentence.split())\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "prompt_1 = PromptTemplate(\n",
    "    template = \"Write a joke on this topic: {topic}\",\n",
    "    input_variables= [\"topic\"]\n",
    ")\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "gen_joke_chain = RunnableSequence(prompt_1, llm, parser)\n",
    "\n",
    "parallel_chain = RunnableParallel({\n",
    "    'joke': RunnablePassthrough(),\n",
    "    'word_count': RunnableLambda(number_words)\n",
    "    #'word_count': RunnableLambda(lambda x: len(x.split()))\n",
    "})\n",
    "\n",
    "final_chain = RunnableSequence(gen_joke_chain, parallel_chain)\n",
    "\n",
    "output = final_chain.invoke({'topic': 'AI'})\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8840e3",
   "metadata": {},
   "source": [
    "## Branch Runnable\n",
    "\n",
    "* for conditional chain: (if, else)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33054ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "India vs Australia cricket match\n",
      "\n",
      "Date: November 27, 2021\n",
      "Venue: Sydney Cricket Ground, Sydney, Australia\n",
      "\n",
      "Introduction:\n",
      "The highly anticipated cricket match between India and Australia took place on November 27, 2021 at the Sydney Cricket Ground in Australia. The match drew in a large audience of cricket fans from both countries, eager to witness the intense rivalry between two of the biggest cricketing nations in the world.\n",
      "\n",
      "First innings:\n",
      "Australia won the toss and elected to bat first. Their top order batsmen got off to a solid start, with openers David Warner and Aaron Finch setting the foundation for a big total. Warner played a stellar innings, scoring a century and anchoring the Australian innings. However, India's bowlers made a strong comeback in the later overs, picking up crucial wickets and restricting Australia to a total of 285/6 in their allotted 50 overs.\n",
      "\n",
      "Second innings:\n",
      "In response, India got off to a shaky start, losing a couple of quick wickets early on. However, captain Virat Kohli and vice-captain Rohit Sharma steadied the ship with a partnership that kept India in the game. Both batsmen played aggressive yet calculated innings, taking on the Australian bowlers with confidence. Despite losing a couple of wickets towards the end, India managed to chase down the target in the final over, with Kohli scoring a brilliant century and leading his team to victory.\n",
      "\n",
      "Key highlights:\n",
      "- David Warner's century for Australia\n",
      "- Virat Kohli's match-winning century for India\n",
      "- Rohit Sharma's crucial partnership with Kohli\n",
      "- Australia's aggressive pace attack\n",
      "- India's disciplined bowling in the middle overs\n",
      "\n",
      "Conclusion:\n",
      "Overall, the India vs Australia cricket match was a thrilling contest that showcased the talent and skill of both teams. The match had several standout performances from individual players, but ultimately it was India who emerged victorious, showcasing their strength and resilience in a high-pressure situation. The win was a significant morale booster for the Indian team, as they look to build momentum heading into upcoming matches.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableSequence, RunnableParallel, RunnablePassthrough, RunnableLambda, RunnableBranch\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "prompt_1 = PromptTemplate(\n",
    "    template= \"Generate a detail report on this topic: {topic}\",\n",
    "    input_variables=[\"topic\"]\n",
    ")\n",
    "\n",
    "prompt_1_1 = PromptTemplate(\n",
    "    template= \"Give me the summary of this report: {report}\",\n",
    "    input_variables=['report']\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "detail_report = RunnableSequence(prompt_1, llm, parser)\n",
    "\n",
    "branch_chain = RunnableBranch(\n",
    "    (lambda x: len(x.split()) > 500, RunnableSequence(prompt_1_1, llm, parser)),\n",
    "    RunnablePassthrough()\n",
    ")\n",
    "\n",
    "final_chain = RunnableSequence(detail_report, branch_chain)\n",
    "\n",
    "output = final_chain.invoke({'topic': 'India vs australia cricket match'})\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314b3f6b",
   "metadata": {},
   "source": [
    "## LCEL: langchain expression language.\n",
    "\n",
    "- RunnableSequence(prompt, llm, parser) --> prompt | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82864533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joke': \"Why did the artificial intelligence break up with its computer? Because it couldn't handle their motherboard's emotional baggage!\", 'word_count': 18}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableSequence, RunnableParallel, RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def number_words(sentence: str):\n",
    "    return len(sentence.split())\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "prompt_1 = PromptTemplate(\n",
    "    template = \"Write a joke on this topic: {topic}\",\n",
    "    input_variables= [\"topic\"]\n",
    ")\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "gen_joke_chain = prompt_1 | llm | parser            # RunnableSequence(prompt_1, llm, parser)\n",
    "\n",
    "parallel_chain = RunnableParallel({\n",
    "    'joke': RunnablePassthrough(),\n",
    "    'word_count': RunnableLambda(number_words)\n",
    "    #'word_count': RunnableLambda(lambda x: len(x.split()))\n",
    "})\n",
    "\n",
    "final_chain =  gen_joke_chain | parallel_chain         # RunnableSequence(gen_joke_chain, parallel_chain)\n",
    "\n",
    "output = final_chain.invoke({'topic': 'AI'})\n",
    "\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
