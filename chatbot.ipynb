{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fe52d60",
   "metadata": {},
   "source": [
    "### Static message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23bc60cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the AI Chatbot! Type 'exit' to quit.\n",
      "AI: Hello! How can I assist you today?\n",
      "AI: Dividing 1000 by 5 gives you 200.\n",
      "AI: Multiplying 200 by 5 gives you 1000.\n",
      "['Hi!', 'Hello! How can I assist you today?', 'DIvide 1000 from 5', 'Dividing 1000 by 5 gives you 200.', 'multiply the result with 5', 'Multiplying 200 by 5 gives you 1000.', 'exit']\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0.5)\n",
    "chat_history = []\n",
    "\n",
    "print(\"Welcome to the AI Chatbot! Type 'exit' to quit.\")\n",
    "while True: \n",
    "    user_input = input(\"You: \")\n",
    "    chat_history.append(user_input)\n",
    "    if user_input == 'exit':\n",
    "        break\n",
    "    else: \n",
    "        result = model.invoke(chat_history)\n",
    "        chat_history.append(result.content)\n",
    "        print(f\"AI: {result.content}\")\n",
    "\n",
    "print(chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1148d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: Hello! How can I assist you today?\n",
      "AI: I am an AI and do not have a personal name. You can refer to me as Assistant or AI. How may I assist you today?\n",
      "AI: I am an artificial intelligence and do not have a physical body or a birthdate. I was created by a team of developers at OpenAI.\n",
      "[SystemMessage(content='Behave like an AI assitant', additional_kwargs={}, response_metadata={}), HumanMessage(content='Hi', additional_kwargs={}, response_metadata={}), AIMessage(content='Hello! How can I assist you today?', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[]), HumanMessage(content='What is your name?', additional_kwargs={}, response_metadata={}), AIMessage(content='I am an AI and do not have a personal name. You can refer to me as Assistant or AI. How may I assist you today?', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[]), HumanMessage(content='Tell me when you born.', additional_kwargs={}, response_metadata={}), AIMessage(content='I am an artificial intelligence and do not have a physical body or a birthdate. I was created by a team of developers at OpenAI.', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[]), HumanMessage(content='exit', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "load_dotenv()\n",
    "model = ChatOpenAI()\n",
    "\n",
    "chat_history = [\n",
    "    SystemMessage(content =  \"Behave like an AI assitant\")\n",
    "]\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    chat_history.append(HumanMessage(content = user_input))\n",
    "    if user_input == \"exit\":\n",
    "        break\n",
    "    else:\n",
    "        result = model.invoke(user_input)\n",
    "        chat_history.append(AIMessage(content = result.content))\n",
    "        print(f\"AI: {result.content}\")\n",
    "\n",
    "print(chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea0aa2f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chat_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6640580",
   "metadata": {},
   "source": [
    "### ChatPromptTemplate: List of meassages (Dynamic Message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e2e2dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='You are a helpful science expert', additional_kwargs={}, response_metadata={}), HumanMessage(content='Explain quantum physics in simple terms.', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "#from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "load_dotenv()\n",
    "model = ChatOpenAI()\n",
    "\n",
    "chat_prompt = ChatPromptTemplate([\n",
    "    #SystemMessage(content = \"You are a helpful {role} expert\"),\n",
    "    #HumanMessage(content = \"Explain {topic} in simple terms.\")\n",
    "    ('system', \"You are a helpful {role} expert\"),\n",
    "    ('human', \"Explain {topic} in simple terms.\")\n",
    "])\n",
    "\n",
    "prompt = chat_prompt.invoke({\n",
    "    \"role\": \"science\",\n",
    "    \"topic\": \"quantum physics\"\n",
    "})\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc3c0e0",
   "metadata": {},
   "source": [
    "### Message Placeholder\n",
    "* To include the chat history. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6036997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HumanMessage(content=\"I want to request a refund for my order #12345.\")', 'AIMessage(content=\"Your refund request for order #12345 has been initiated. It will be processed in 3-5 business days.\")']\n",
      "AI: I'm happy to look into that for you. Could you please provide me with your order number so I can track the status of your refund accurately?\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "load_dotenv()\n",
    "model = ChatOpenAI()\n",
    "\n",
    "template = ChatPromptTemplate([\n",
    "    ('system', 'You are a helpful customer care.'),\n",
    "    MessagesPlaceholder(variable_name = 'chat_history'),\n",
    "    ('human', '{query}')\n",
    "])\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "with open(\"chat_history.txt\") as f:\n",
    "    chat_history.extend(f.read().splitlines())\n",
    "\n",
    "print(chat_history)\n",
    "\n",
    "query = \"Where is my refund?\"\n",
    "\n",
    "final_prompt = template.invoke({\n",
    "    \"chat_history\": chat_history,\n",
    "    \"query\": query\n",
    "})\n",
    "\n",
    "result = model.invoke(final_prompt)\n",
    "print(f\"AI: {result.content}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
